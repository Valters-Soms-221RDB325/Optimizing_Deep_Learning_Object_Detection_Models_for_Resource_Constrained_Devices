{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade pip setuptools\n",
        "!pip install -q \"numpy~=1.26.4\"\n",
        "!pip install -q nncf==2.8.0\n",
        "!pip install -q ultralytics openvino-dev tqdm requests PyYAML\n"
      ],
      "metadata": {
        "id": "7y4V5cB8T5yW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from openvino.runtime import Core\n",
        "    print(f\"Torch: {torch.__version__}, NumPy: {np.__version__}, OpenVINO: {Core().get_versions('CPU')['CPU']}\")\n",
        "    import networkx as nx\n",
        "except ImportError as e:\n",
        "    print(f\"A core library not fully imported: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"Import/version check error: {e}\")"
      ],
      "metadata": {
        "id": "r1V4O1xDLRqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/my_coco_data/images"
      ],
      "metadata": {
        "id": "i7xuqhzJMKsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ielādē datu kopas vispirms\n",
        "!unzip /content/val2017.zip -d /content/my_coco_data/images/\n",
        "!unzip /content/annotations_trainval2017.zip -d /content/my_coco_data"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6n4pMlKuT6DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT_DIR = \"/content/my_coco_data\"\n",
        "\n",
        "MODEL_PT = 'yolo11l.pt'\n",
        "EXPORT_DIR_BASE = 'exported_models_coco_val2017'\n",
        "\n",
        "IMAGES_SUBDIR_RELATIVE = \"images/val2017\"\n",
        "JSON_ANNOTATION_SUBDIR_RELATIVE = \"annotations/instances_val2017.json\"\n",
        "LABELS_SUBDIR_RELATIVE = \"labels/val2017\"\n",
        "\n",
        "ABS_IMAGES_DIR = Path(DATASET_ROOT_DIR) / IMAGES_SUBDIR_RELATIVE\n",
        "ABS_JSON_ANNOTATION_FILE = Path(DATASET_ROOT_DIR) / JSON_ANNOTATION_SUBDIR_RELATIVE\n",
        "ABS_LABELS_DIR = Path(DATASET_ROOT_DIR) / LABELS_SUBDIR_RELATIVE\n",
        "\n",
        "DATASET_YAML_NAME = \"coco_val2017_for_yolo.yaml\"\n",
        "ABS_DATASET_YAML_PATH = f\"/content/{DATASET_YAML_NAME}\"\n",
        "\n",
        "COCO_CLASSES = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
        "    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
        "    'hair drier', 'toothbrush'\n",
        "]"
      ],
      "metadata": {
        "id": "qQOHyXXdT6Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_coco_json_to_yolo_txt(json_annotation_path_abs, image_dir_path_abs, output_label_dir_path_abs, class_names_list):\n",
        "    if not json_annotation_path_abs.is_file():\n",
        "        print(f\"ERROR: JSON Annotation file not found at {json_annotation_path_abs}.\")\n",
        "        return False\n",
        "    os.makedirs(output_label_dir_path_abs, exist_ok=True)\n",
        "    try:\n",
        "        with open(json_annotation_path_abs, 'r') as f:\n",
        "            data = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading JSON file {json_annotation_path_abs}: {e}\")\n",
        "        return False\n",
        "    if 'categories' not in data or 'images' not in data or 'annotations' not in data:\n",
        "        print(f\"ERROR: JSON file {json_annotation_path_abs} is missing 'categories', 'images', or 'annotations' key.\")\n",
        "        return False\n",
        "\n",
        "    coco_id_to_name_from_json = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    name_to_target_id = {name: i for i, name in enumerate(class_names_list)}\n",
        "    coco_cat_id_to_target_id = {}\n",
        "    for coco_id, coco_name in coco_id_to_name_from_json.items():\n",
        "        if coco_name in name_to_target_id:\n",
        "            coco_cat_id_to_target_id[coco_id] = name_to_target_id[coco_name]\n",
        "\n",
        "    image_info_map = {img['id']: {'file_name': img['file_name'],\n",
        "                                  'width': img['width'],\n",
        "                                  'height': img['height']}\n",
        "                      for img in data['images']}\n",
        "    annotations_per_image = {}\n",
        "    for ann in data['annotations']:\n",
        "        image_id = ann['image_id']\n",
        "        if image_id not in annotations_per_image:\n",
        "            annotations_per_image[image_id] = []\n",
        "        annotations_per_image[image_id].append(ann)\n",
        "    files_created_count = 0\n",
        "    for image_id, anns_list in tqdm(annotations_per_image.items(), desc=f\"Converting {json_annotation_path_abs.name}\", leave=False):\n",
        "        if image_id not in image_info_map:\n",
        "            continue\n",
        "        img_data = image_info_map[image_id]\n",
        "        img_filename_base = Path(img_data['file_name']).stem\n",
        "        img_width = img_data['width']\n",
        "        img_height = img_data['height']\n",
        "        if img_width == 0 or img_height == 0:\n",
        "            continue\n",
        "        yolo_label_path = output_label_dir_path_abs / f\"{img_filename_base}.txt\"\n",
        "        with open(yolo_label_path, 'w') as f_out:\n",
        "            for ann_data in anns_list:\n",
        "                coco_cat_id = ann_data['category_id']\n",
        "                if coco_cat_id in coco_cat_id_to_target_id:\n",
        "                    target_class_id = coco_cat_id_to_target_id[coco_cat_id]\n",
        "                    bbox_coco = ann_data['bbox']\n",
        "                    x_min, y_min, w, h = bbox_coco\n",
        "                    x_center = x_min + w / 2\n",
        "                    y_center = y_min + h / 2\n",
        "                    x_center_norm = x_center / img_width\n",
        "                    y_center_norm = y_center / img_height\n",
        "                    width_norm = w / img_width\n",
        "                    height_norm = h / img_height\n",
        "                    f_out.write(f\"{target_class_id} {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\\n\")\n",
        "        files_created_count += 1\n",
        "    if files_created_count == 0 and len(annotations_per_image) > 0 :\n",
        "        print(\"WARNING: No label files were created. Check paths, image ID matching, and category mapping.\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "hrlMfUqrT6II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(ABS_LABELS_DIR):\n",
        "    shutil.rmtree(ABS_LABELS_DIR)\n",
        "yolo_cache_file = ABS_LABELS_DIR.parent / (ABS_LABELS_DIR.name + \".cache\")\n",
        "if yolo_cache_file.exists():\n",
        "    os.remove(yolo_cache_file)\n",
        "yolo_cache_file_inside = ABS_LABELS_DIR / (ABS_LABELS_DIR.name + \".cache\")\n",
        "if yolo_cache_file_inside.exists():\n",
        "     os.remove(yolo_cache_file_inside)\n",
        "\n",
        "conversion_successful = convert_coco_json_to_yolo_txt(\n",
        "    ABS_JSON_ANNOTATION_FILE,\n",
        "    ABS_IMAGES_DIR,\n",
        "    ABS_LABELS_DIR,\n",
        "    COCO_CLASSES\n",
        ")\n",
        "\n",
        "if conversion_successful:\n",
        "    yaml_content = f\"\"\"\n",
        "path: {DATASET_ROOT_DIR}\n",
        "train: {IMAGES_SUBDIR_RELATIVE}\n",
        "val: {IMAGES_SUBDIR_RELATIVE}\n",
        "\n",
        "names:\n",
        "\"\"\"\n",
        "    for i, name in enumerate(COCO_CLASSES):\n",
        "        yaml_content += f\"  {i}: {name}\\n\"\n",
        "    try:\n",
        "        with open(ABS_DATASET_YAML_PATH, 'w') as f:\n",
        "            f.write(yaml_content)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to write YAML file: {e}\")\n",
        "        ABS_DATASET_YAML_PATH = None\n",
        "else:\n",
        "    print(\"ERROR: Label conversion failed. YAML file will not be created.\")\n",
        "    ABS_DATASET_YAML_PATH = None"
      ],
      "metadata": {
        "id": "DPvI6V71T6KP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5d5cbe-df41-4660-c434-81e35331db80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_summary = {}\n",
        "yolo_base_model = None\n",
        "\n",
        "def validate_and_store_results(model_to_eval, model_id_str, data_yaml_path, device_str='cuda'):\n",
        "    \"\"\"Helper to validate a model and store its metrics.\"\"\"\n",
        "    print(f\"\\n--- Validating: {model_id_str} on {device_str} ---\")\n",
        "    metrics_data = {\n",
        "        \"mAP50-95\": float('nan'), \"mAP50\": float('nan'), \"mAP75\": float('nan'),\n",
        "        \"Precision\": float('nan'), \"Recall\": float('nan'), \"F1\": float('nan')\n",
        "    }\n",
        "    try:\n",
        "        metrics_obj = model_to_eval.val(data=data_yaml_path, split='val', device=device_str, plots=False, batch=1)\n",
        "\n",
        "        if metrics_obj and hasattr(metrics_obj, 'box') and hasattr(metrics_obj.box, 'map'):\n",
        "            metrics_data[\"mAP50-95\"] = metrics_obj.box.map\n",
        "            metrics_data[\"mAP50\"] = metrics_obj.box.map50\n",
        "            metrics_data[\"mAP75\"] = metrics_obj.box.map75\n",
        "\n",
        "            if hasattr(metrics_obj.box, 'p') and isinstance(metrics_obj.box.p, np.ndarray) and metrics_obj.box.p.size > 0:\n",
        "                metrics_data[\"Precision\"] = np.mean(metrics_obj.box.p)\n",
        "            elif hasattr(metrics_obj.box, 'p'):\n",
        "                metrics_data[\"Precision\"] = metrics_obj.box.p\n",
        "\n",
        "            if hasattr(metrics_obj.box, 'r') and isinstance(metrics_obj.box.r, np.ndarray) and metrics_obj.box.r.size > 0:\n",
        "                metrics_data[\"Recall\"] = np.mean(metrics_obj.box.r)\n",
        "            elif hasattr(metrics_obj.box, 'r'):\n",
        "                metrics_data[\"Recall\"] = metrics_obj.box.r\n",
        "\n",
        "            if hasattr(metrics_obj.box, 'f1') and isinstance(metrics_obj.box.f1, np.ndarray) and metrics_obj.box.f1.size > 0:\n",
        "                metrics_data[\"F1\"] = np.mean(metrics_obj.box.f1)\n",
        "            elif hasattr(metrics_obj.box, 'f1'):\n",
        "                 metrics_data[\"F1\"] = metrics_obj.box.f1\n",
        "\n",
        "        print(f\"Metrics for {model_id_str}: mAP50={metrics_data['mAP50']:.4f}, P={metrics_data['Precision']:.4f}, R={metrics_data['Recall']:.4f}, F1={metrics_data['F1']:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR during validation of {model_id_str}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        for key in [\"mAP50-95\", \"mAP50\", \"mAP75\", \"Precision\", \"Recall\", \"F1\"]:\n",
        "            metrics_data.setdefault(key, float('nan'))\n",
        "\n",
        "    results_summary[model_id_str] = metrics_data\n",
        "\n",
        "if ABS_DATASET_YAML_PATH and Path(ABS_DATASET_YAML_PATH).exists():\n",
        "    print(f\"\\n[INFO] Loading PyTorch base model: {MODEL_PT}\")\n",
        "    yolo_base_model = YOLO(MODEL_PT)\n",
        "\n",
        "    if yolo_base_model:\n",
        "        print(\"\\n[INFO] Exporting to OpenVINO FP32...\")\n",
        "        try:\n",
        "            fp32_export_path_obj = yolo_base_model.export(\n",
        "                format='openvino',\n",
        "                half=False,\n",
        "                project=EXPORT_DIR_BASE,\n",
        "                name=f\"{Path(MODEL_PT).stem}_ov_fp32\"\n",
        "            )\n",
        "            fp32_ov_model_path = str(fp32_export_path_obj)\n",
        "            print(f\"OpenVINO FP32 model exported to: {fp32_ov_model_path}\")\n",
        "            ov_fp32_yolo = YOLO(fp32_ov_model_path)\n",
        "            validate_and_store_results(ov_fp32_yolo, \"OpenVINO FP32\", ABS_DATASET_YAML_PATH, device_str='cpu')\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR during OpenVINO FP32 export or validation: {e}\")\n",
        "            results_summary[\"OpenVINO FP32\"] = {key: float('nan') for key in [\"mAP50-95\", \"mAP50\", \"mAP75\", \"Precision\", \"Recall\", \"F1\"]}\n",
        "\n",
        "    if yolo_base_model:\n",
        "        print(\"\\n[INFO] Exporting to OpenVINO INT8 (calibration with val2017 .txt labels)...\")\n",
        "        try:\n",
        "            int8_export_path_obj = yolo_base_model.export(\n",
        "                format='openvino',\n",
        "                int8=True,\n",
        "                data=ABS_DATASET_YAML_PATH,\n",
        "                project=EXPORT_DIR_BASE,\n",
        "                name=f\"{Path(MODEL_PT).stem}_ov_int8\"\n",
        "            )\n",
        "            int8_ov_model_path = str(int8_export_path_obj)\n",
        "            print(f\"OpenVINO INT8 model exported to: {int8_ov_model_path}\")\n",
        "            ov_int8_yolo = YOLO(int8_ov_model_path)\n",
        "            validate_and_store_results(ov_int8_yolo, \"OpenVINO INT8\", ABS_DATASET_YAML_PATH, device_str='cpu')\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR during OpenVINO INT8 export or validation: {e}\")\n",
        "            results_summary[\"OpenVINO INT8\"] = {key: float('nan') for key in [\"mAP50-95\", \"mAP50\", \"mAP75\", \"Precision\", \"Recall\", \"F1\"]}\n",
        "else:\n",
        "    print(\"ERROR: Dataset YAML path is not valid. Cannot proceed with evaluations.\")\n",
        "\n",
        "print(\"\\nCell 5: Model evaluations executed.\")"
      ],
      "metadata": {
        "id": "2U6d23KYT6MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n--- Overall Performance Summary (val2017 on CPU) ---\")\n",
        "header = (f\"{'Model':<25} | {'mAP@.5':<10} | {'mAP@.75':<10} | {'mAP@.5-.95':<12} | \"\n",
        "          f\"{'Precision':<10} | {'Recall':<10} | {'F1-score':<10}\")\n",
        "separator = \"-\" * (len(header) + 5)\n",
        "\n",
        "print(header)\n",
        "print(separator)\n",
        "\n",
        "def get_metric_value(metric_data):\n",
        "    if isinstance(metric_data, (np.ndarray, list)):\n",
        "        if len(metric_data) > 0:\n",
        "            return np.mean(metric_data)\n",
        "        return float('nan')\n",
        "    return metric_data\n",
        "\n",
        "model_order = [\"PyTorch FP32\", \"OpenVINO FP32\", \"OpenVINO INT8\"]\n",
        "evaluated_models_in_order = [m for m in model_order if m in results_summary]\n",
        "remaining_models = [m for m in results_summary if m not in evaluated_models_in_order]\n",
        "final_print_order = evaluated_models_in_order + remaining_models\n",
        "\n",
        "\n",
        "for model_name in final_print_order:\n",
        "    metrics = results_summary.get(model_name, {})\n",
        "    map_val = metrics.get(\"mAP50-95\", float('nan'))\n",
        "    map50_val = metrics.get(\"mAP50\", float('nan'))\n",
        "    map75_val = metrics.get(\"mAP75\", float('nan'))\n",
        "\n",
        "    precision_val = metrics.get(\"Precision\", float('nan'))\n",
        "    recall_val = metrics.get(\"Recall\", float('nan'))\n",
        "    f1_val = metrics.get(\"F1\", float('nan'))\n",
        "\n",
        "    print(f\"{model_name:<25} | {map50_val:<10.4f} | {map75_val:<10.4f} | {map_val:<12.4f} | \"\n",
        "          f\"{precision_val:<10.4f} | {recall_val:<10.4f} | {f1_val:<10.4f}\")\n",
        "\n",
        "print(\"\\nCell 6: Results summary executed.\")"
      ],
      "metadata": {
        "id": "5ybMPcmjT6Ob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}