{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade pip setuptools\n",
        "!pip install -q \"numpy~=1.26.4\"\n",
        "!pip install -q ultralytics tqdm requests PyYAML\n",
        "!pip install -q onnx==1.17.0 onnxruntime==1.22.0 onnxconverter-common==1.14.0\n"
      ],
      "metadata": {
        "id": "dhvrM6F2K8O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/my_coco_data/images\n",
        "!unzip -q /content/val2017.zip -d /content/my_coco_data/images/\n",
        "!unzip -q /content/annotations_trainval2017.zip -d /content/my_coco_data"
      ],
      "metadata": {
        "id": "uvVOCwI6IkUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    import onnx\n",
        "    import onnxruntime as ort\n",
        "    from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantFormat, QuantType\n",
        "except ImportError:\n",
        "    print(\"ONNX libraries not found, ensure they are installed in the next cell.\")\n",
        "\n",
        "print(f\"Torch: {torch.__version__}, NumPy: {np.__version__}\")\n",
        "DATASET_ROOT_DIR = \"/content/my_coco_data\"\n",
        "MODEL_PT = 'yolo11m.pt'\n",
        "EXPORT_DIR_BASE = 'exported_models_coco_val2017'\n",
        "\n",
        "IMAGES_SUBDIR_RELATIVE = \"images/val2017\"\n",
        "JSON_ANNOTATION_SUBDIR_RELATIVE = \"annotations/instances_val2017.json\"\n",
        "LABELS_SUBDIR_RELATIVE = \"labels/val2017\"\n",
        "\n",
        "ABS_IMAGES_DIR = Path(DATASET_ROOT_DIR) / IMAGES_SUBDIR_RELATIVE\n",
        "ABS_JSON_ANNOTATION_FILE = Path(DATASET_ROOT_DIR) / JSON_ANNOTATION_SUBDIR_RELATIVE\n",
        "ABS_LABELS_DIR = Path(DATASET_ROOT_DIR) / LABELS_SUBDIR_RELATIVE\n",
        "\n",
        "DATASET_YAML_NAME = \"coco_val2017_for_yolo.yaml\"\n",
        "ABS_DATASET_YAML_PATH = f\"/content/{DATASET_YAML_NAME}\"\n",
        "\n",
        "COCO_CLASSES = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
        "    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
        "    'hair drier', 'toothbrush'\n",
        "]"
      ],
      "metadata": {
        "id": "Gqe_x__4iSdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_coco_json_to_yolo_txt(json_annotation_path_abs, image_dir_path_abs, output_label_dir_path_abs, class_names_list):\n",
        "    if not json_annotation_path_abs.is_file():\n",
        "        print(f\"ERROR: JSON Annotation file not found: {json_annotation_path_abs}\")\n",
        "        return False\n",
        "    os.makedirs(output_label_dir_path_abs, exist_ok=True)\n",
        "    try:\n",
        "        with open(json_annotation_path_abs, 'r') as f: data = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading JSON {json_annotation_path_abs}: {e}\"); return False\n",
        "    if not all(k in data for k in ['categories', 'images', 'annotations']):\n",
        "        print(f\"ERROR: JSON {json_annotation_path_abs} missing keys.\"); return False\n",
        "\n",
        "    coco_id_to_name = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    name_to_target_id = {name: i for i, name in enumerate(class_names_list)}\n",
        "    coco_cat_id_to_target_id = {cid: name_to_target_id[cname] for cid, cname in coco_id_to_name.items() if cname in name_to_target_id}\n",
        "    image_info = {img['id']: {'fn': img['file_name'], 'w': img['width'], 'h': img['height']} for img in data['images']}\n",
        "    img_ann = {}\n",
        "    for ann in data['annotations']:\n",
        "        img_id = ann['image_id']\n",
        "        if img_id not in img_ann: img_ann[img_id] = []\n",
        "        img_ann[img_id].append(ann)\n",
        "    created_count = 0\n",
        "    for img_id, anns in tqdm(img_ann.items(), desc=f\"Converting {json_annotation_path_abs.name}\", leave=False):\n",
        "        if img_id not in image_info: continue\n",
        "        img_d = image_info[img_id]\n",
        "        if img_d['w'] == 0 or img_d['h'] == 0: continue\n",
        "        with open(output_label_dir_path_abs / f\"{Path(img_d['fn']).stem}.txt\", 'w') as f_out:\n",
        "            for ann_d in anns:\n",
        "                if ann_d['category_id'] in coco_cat_id_to_target_id:\n",
        "                    cls_id = coco_cat_id_to_target_id[ann_d['category_id']]\n",
        "                    x, y, w, h = ann_d['bbox']\n",
        "                    xc, yc = (x + w / 2) / img_d['w'], (y + h / 2) / img_d['h']\n",
        "                    wn, hn = w / img_d['w'], h / img_d['h']\n",
        "                    f_out.write(f\"{cls_id} {xc:.6f} {yc:.6f} {wn:.6f} {hn:.6f}\\n\")\n",
        "            created_count += 1\n",
        "    if created_count == 0 and img_ann: print(\"WARNING: No labels created.\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "sa1kryfSInf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(ABS_LABELS_DIR): shutil.rmtree(ABS_LABELS_DIR)\n",
        "_paths_to_check_for_cache = [ABS_LABELS_DIR.parent, ABS_LABELS_DIR, Path(ABS_DATASET_YAML_PATH).parent]\n",
        "for pth in _paths_to_check_for_cache:\n",
        "    if pth.exists():\n",
        "        for cache_file in pth.glob('*.cache'):\n",
        "            if cache_file.is_file() and (Path(ABS_DATASET_YAML_PATH).stem in cache_file.name or ABS_LABELS_DIR.name in cache_file.name):\n",
        "                os.remove(cache_file)\n",
        "\n",
        "conversion_successful = convert_coco_json_to_yolo_txt(ABS_JSON_ANNOTATION_FILE, ABS_IMAGES_DIR, ABS_LABELS_DIR, COCO_CLASSES)\n",
        "\n",
        "ABS_DATASET_YAML_PATH = f\"/content/{DATASET_YAML_NAME}\"\n",
        "if conversion_successful:\n",
        "    yaml_content = f\"path: {DATASET_ROOT_DIR}\\ntrain: {IMAGES_SUBDIR_RELATIVE}\\nval: {IMAGES_SUBDIR_RELATIVE}\\n\\nnames:\\n\"\n",
        "    for i, name in enumerate(COCO_CLASSES): yaml_content += f\"  {i}: {name}\\n\"\n",
        "    try:\n",
        "        with open(ABS_DATASET_YAML_PATH, 'w') as f: f.write(yaml_content)\n",
        "        if not Path(ABS_DATASET_YAML_PATH).is_file(): ABS_DATASET_YAML_PATH = None\n",
        "    except Exception as e: print(f\"ERROR writing YAML: {e}\"); ABS_DATASET_YAML_PATH = None\n",
        "else:\n",
        "    print(\"ERROR: Label conversion failed. YAML not created.\"); ABS_DATASET_YAML_PATH = None\n",
        "\n",
        "if not (ABS_DATASET_YAML_PATH and Path(ABS_DATASET_YAML_PATH).exists()):\n",
        "    print(\"FATAL: Dataset YAML creation failed or path invalid. Evaluation cannot proceed.\")\n",
        "else:\n",
        "    print(f\"Dataset YAML ready: {ABS_DATASET_YAML_PATH}\")"
      ],
      "metadata": {
        "id": "nS08RNKBIphx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_summary = {}\n",
        "yolo_base_model = None\n",
        "\n",
        "class ONNXCOCOCalibrationDataReader(CalibrationDataReader):\n",
        "    def __init__(self, dataset_yaml_path, model_input_name, num_calibration_images=128, input_size=(640, 640)):\n",
        "        self.model_input_name = model_input_name\n",
        "        self.num_calibration_images = num_calibration_images\n",
        "        self.input_size = input_size\n",
        "        self.image_files = self._load_image_paths_from_yaml(dataset_yaml_path)\n",
        "        if len(self.image_files) > self.num_calibration_images:\n",
        "            selected_indices = np.random.choice(len(self.image_files), self.num_calibration_images, replace=False)\n",
        "            self.image_files = [self.image_files[i] for i in selected_indices]\n",
        "        elif not self.image_files: raise ValueError(\"No training images for ONNX calibration.\")\n",
        "        self.data_iter = iter(self._preprocess_images())\n",
        "\n",
        "    def _load_image_paths_from_yaml(self, yaml_path):\n",
        "        import yaml\n",
        "        with open(yaml_path, 'r') as f: data = yaml.safe_load(f)\n",
        "        dataset_root = Path(data.get('path', Path(yaml_path).parent))\n",
        "        train_images_rel_path = data.get('train')\n",
        "        if not train_images_rel_path: return []\n",
        "        abs_train_dir = dataset_root / train_images_rel_path\n",
        "        img_paths = []\n",
        "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tif', '*.tiff']:\n",
        "            img_paths.extend(list(abs_train_dir.glob(ext)))\n",
        "        return img_paths\n",
        "\n",
        "    def _preprocess_images(self):\n",
        "        from PIL import Image\n",
        "        for image_path in tqdm(self.image_files, desc=\"Preprocessing ONNX calib\", leave=False):\n",
        "            try:\n",
        "                img = Image.open(image_path).convert('RGB').resize(self.input_size[::-1], Image.LANCZOS)\n",
        "                img_np = (np.array(img, dtype=np.float32) / 255.0).transpose(2, 0, 1)\n",
        "                yield {self.model_input_name: img_np[np.newaxis, ...]}\n",
        "            except Exception: continue\n",
        "    def get_next(self): return next(self.data_iter, None)\n",
        "    def rewind(self): self.data_iter = iter(self._preprocess_images())\n",
        "\n",
        "def validate_and_store_results(model_to_eval, model_id_str, data_yaml_path, device_str='cpu'):\n",
        "    global results_summary\n",
        "    metrics_data = {\n",
        "        \"mAP50-95\": float('nan'), \"mAP50\": float('nan'), \"mAP75\": float('nan'),\n",
        "        \"Precision\": float('nan'), \"Recall\": float('nan'), \"F1\": float('nan')\n",
        "    }\n",
        "    try:\n",
        "        model = YOLO(str(model_to_eval)) if isinstance(model_to_eval, (str, Path)) else model_to_eval\n",
        "        m_obj = model.val(data=data_yaml_path, split='val', device=device_str, plots=False, batch=1, verbose=False)\n",
        "\n",
        "        if m_obj and hasattr(m_obj, 'box') and hasattr(m_obj.box, 'map'):\n",
        "            metrics_data.update({\"mAP50-95\": m_obj.box.map, \"mAP50\": m_obj.box.map50, \"mAP75\": m_obj.box.map75})\n",
        "            for metric_key, ultralytics_key in [(\"Precision\", 'p'), (\"Recall\", 'r'), (\"F1\", 'f1')]:\n",
        "                if hasattr(m_obj.box, ultralytics_key):\n",
        "                    val = getattr(m_obj.box, ultralytics_key)\n",
        "                    metrics_data[metric_key] = np.mean(val) if isinstance(val, np.ndarray) and val.size > 0 else val\n",
        "\n",
        "        print(f\"Metrics for {model_id_str}: mAP50={metrics_data['mAP50']:.4f}, P={metrics_data['Precision']:.4f}, R={metrics_data['Recall']:.4f}, F1={metrics_data['F1']:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR validating {model_id_str}: {e}\")\n",
        "        for key in [\"mAP50-95\", \"mAP50\", \"mAP75\", \"Precision\", \"Recall\", \"F1\"]:\n",
        "            metrics_data.setdefault(key, float('nan'))\n",
        "\n",
        "    results_summary[model_id_str] = metrics_data"
      ],
      "metadata": {
        "id": "lrtZ4AqqIrYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Overall Performance Summary (val2017 on CPU) ---\")\n",
        "header = (f\"{'Model':<30} | {'mAP@.5':<10} | {'mAP@.75':<10} | {'mAP@.5-.95':<12} | \"\n",
        "          f\"{'Precision':<10} | {'Recall':<10} | {'F1-score':<10}\")\n",
        "separator = \"-\" * len(header)\n",
        "print(header)\n",
        "print(separator)\n",
        "\n",
        "model_order = [\"PyTorch FP32\", \"ONNX FP32\", \"ONNX INT8\"]\n",
        "evaluated_models_in_order = [m for m in model_order if m in results_summary]\n",
        "remaining_models = [m for m in results_summary if m not in evaluated_models_in_order]\n",
        "final_print_order = evaluated_models_in_order + remaining_models\n",
        "\n",
        "for model_name in final_print_order:\n",
        "    metrics = results_summary.get(model_name, {})\n",
        "    map_val = metrics.get(\"mAP50-95\", float('nan'))\n",
        "    map50_val = metrics.get(\"mAP50\", float('nan'))\n",
        "    map75_val = metrics.get(\"mAP75\", float('nan'))\n",
        "    precision_val = metrics.get(\"Precision\", float('nan'))\n",
        "    recall_val = metrics.get(\"Recall\", float('nan'))\n",
        "    f1_val = metrics.get(\"F1\", float('nan'))\n",
        "\n",
        "    print(f\"{model_name:<30} | {map50_val:<10.4f} | {map75_val:<10.4f} | {map_val:<12.4f} | \"\n",
        "          f\"{precision_val:<10.4f} | {recall_val:<10.4f} | {f1_val:<10.4f}\")\n",
        "\n",
        "if not results_summary: print(\"No results to display.\")"
      ],
      "metadata": {
        "id": "8KvNS5hDIwXD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}