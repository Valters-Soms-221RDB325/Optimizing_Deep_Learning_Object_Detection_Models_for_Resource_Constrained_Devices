{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade pip setuptools\n",
        "!pip install -q \"numpy~=1.26.4\"\n",
        "!pip install -q ultralytics openvino-dev tqdm requests PyYAML\n",
        "\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "try:\n",
        "    from openvino.runtime import Core\n",
        "    print(f\"OpenVINO version: {Core().get_versions('CPU')['CPU']}\")\n",
        "    import networkx as nx\n",
        "    print(f\"NetworkX version: {nx.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"One of the core libraries (OpenVINO, NetworkX) not fully imported, check installation: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during import or version check: {e}\")"
      ],
      "metadata": {
        "id": "7y4V5cB8T5yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/my_coco_data/images"
      ],
      "metadata": {
        "id": "i7xuqhzJMKsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ielādē datu kopas vispirms\n",
        "!unzip /content/val2017.zip -d /content/my_coco_data/images/\n",
        "!unzip /content/annotations_trainval2017.zip -d /content/my_coco_data"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6n4pMlKuT6DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT_DIR = \"/content/my_coco_data\"\n",
        "\n",
        "MODEL_PT = 'yolo11x.pt'\n",
        "EXPORT_DIR_BASE = 'exported_models_coco_val2017'\n",
        "\n",
        "IMAGES_SUBDIR_RELATIVE = \"images/val2017\"\n",
        "JSON_ANNOTATION_SUBDIR_RELATIVE = \"annotations/instances_val2017.json\"\n",
        "LABELS_SUBDIR_RELATIVE = \"labels/val2017\"\n",
        "\n",
        "ABS_IMAGES_DIR = Path(DATASET_ROOT_DIR) / IMAGES_SUBDIR_RELATIVE\n",
        "ABS_JSON_ANNOTATION_FILE = Path(DATASET_ROOT_DIR) / JSON_ANNOTATION_SUBDIR_RELATIVE\n",
        "ABS_LABELS_DIR = Path(DATASET_ROOT_DIR) / LABELS_SUBDIR_RELATIVE\n",
        "\n",
        "DATASET_YAML_NAME = \"coco_val2017_for_yolo.yaml\"\n",
        "ABS_DATASET_YAML_PATH = f\"/content/{DATASET_YAML_NAME}\"\n",
        "\n",
        "COCO_CLASSES = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
        "    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
        "    'hair drier', 'toothbrush'\n",
        "]"
      ],
      "metadata": {
        "id": "qQOHyXXdT6Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_coco_json_to_yolo_txt(json_annotation_path_abs, image_dir_path_abs, output_label_dir_path_abs, class_names_list):\n",
        "    if not json_annotation_path_abs.is_file():\n",
        "        print(f\"ERROR: JSON Annotation file not found at {json_annotation_path_abs}.\")\n",
        "        return False\n",
        "    os.makedirs(output_label_dir_path_abs, exist_ok=True)\n",
        "    try:\n",
        "        with open(json_annotation_path_abs, 'r') as f:\n",
        "            data = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading JSON file {json_annotation_path_abs}: {e}\")\n",
        "        return False\n",
        "    if 'categories' not in data or 'images' not in data or 'annotations' not in data:\n",
        "        print(f\"ERROR: JSON file {json_annotation_path_abs} is missing 'categories', 'images', or 'annotations' key.\")\n",
        "        return False\n",
        "\n",
        "    coco_id_to_name_from_json = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    name_to_target_id = {name: i for i, name in enumerate(class_names_list)}\n",
        "    coco_cat_id_to_target_id = {}\n",
        "    for coco_id, coco_name in coco_id_to_name_from_json.items():\n",
        "        if coco_name in name_to_target_id:\n",
        "            coco_cat_id_to_target_id[coco_id] = name_to_target_id[coco_name]\n",
        "\n",
        "    image_info_map = {img['id']: {'file_name': img['file_name'],\n",
        "                                  'width': img['width'],\n",
        "                                  'height': img['height']}\n",
        "                      for img in data['images']}\n",
        "    annotations_per_image = {}\n",
        "    for ann in data['annotations']:\n",
        "        image_id = ann['image_id']\n",
        "        if image_id not in annotations_per_image:\n",
        "            annotations_per_image[image_id] = []\n",
        "        annotations_per_image[image_id].append(ann)\n",
        "    files_created_count = 0\n",
        "    for image_id, anns_list in tqdm(annotations_per_image.items(), desc=f\"Converting {json_annotation_path_abs.name}\", leave=False):\n",
        "        if image_id not in image_info_map:\n",
        "            continue\n",
        "        img_data = image_info_map[image_id]\n",
        "        img_filename_base = Path(img_data['file_name']).stem\n",
        "        img_width = img_data['width']\n",
        "        img_height = img_data['height']\n",
        "        if img_width == 0 or img_height == 0:\n",
        "            continue\n",
        "        yolo_label_path = output_label_dir_path_abs / f\"{img_filename_base}.txt\"\n",
        "        with open(yolo_label_path, 'w') as f_out:\n",
        "            for ann_data in anns_list:\n",
        "                coco_cat_id = ann_data['category_id']\n",
        "                if coco_cat_id in coco_cat_id_to_target_id:\n",
        "                    target_class_id = coco_cat_id_to_target_id[coco_cat_id]\n",
        "                    bbox_coco = ann_data['bbox']\n",
        "                    x_min, y_min, w, h = bbox_coco\n",
        "                    x_center = x_min + w / 2\n",
        "                    y_center = y_min + h / 2\n",
        "                    x_center_norm = x_center / img_width\n",
        "                    y_center_norm = y_center / img_height\n",
        "                    width_norm = w / img_width\n",
        "                    height_norm = h / img_height\n",
        "                    f_out.write(f\"{target_class_id} {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\\n\")\n",
        "        files_created_count += 1\n",
        "    if files_created_count == 0 and len(annotations_per_image) > 0 :\n",
        "        print(\"WARNING: No label files were created. Check paths, image ID matching, and category mapping.\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "hrlMfUqrT6II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(ABS_LABELS_DIR):\n",
        "    shutil.rmtree(ABS_LABELS_DIR)\n",
        "yolo_cache_file = ABS_LABELS_DIR.parent / (ABS_LABELS_DIR.name + \".cache\")\n",
        "if yolo_cache_file.exists():\n",
        "    os.remove(yolo_cache_file)\n",
        "yolo_cache_file_inside = ABS_LABELS_DIR / (ABS_LABELS_DIR.name + \".cache\")\n",
        "if yolo_cache_file_inside.exists():\n",
        "     os.remove(yolo_cache_file_inside)\n",
        "\n",
        "conversion_successful = convert_coco_json_to_yolo_txt(\n",
        "    ABS_JSON_ANNOTATION_FILE,\n",
        "    ABS_IMAGES_DIR,\n",
        "    ABS_LABELS_DIR,\n",
        "    COCO_CLASSES\n",
        ")\n",
        "\n",
        "if conversion_successful:\n",
        "    yaml_content = f\"\"\"\n",
        "path: {DATASET_ROOT_DIR}\n",
        "train: {IMAGES_SUBDIR_RELATIVE}\n",
        "val: {IMAGES_SUBDIR_RELATIVE}\n",
        "\n",
        "names:\n",
        "\"\"\"\n",
        "    for i, name in enumerate(COCO_CLASSES):\n",
        "        yaml_content += f\"  {i}: {name}\\n\"\n",
        "    try:\n",
        "        with open(ABS_DATASET_YAML_PATH, 'w') as f:\n",
        "            f.write(yaml_content)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to write YAML file: {e}\")\n",
        "        ABS_DATASET_YAML_PATH = None\n",
        "else:\n",
        "    print(\"ERROR: Label conversion failed. YAML file will not be created.\")\n",
        "    ABS_DATASET_YAML_PATH = None"
      ],
      "metadata": {
        "id": "DPvI6V71T6KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_summary = {}\n",
        "yolo_base_model = None\n",
        "\n",
        "def validate_and_store_results(model_to_eval, model_id_str, data_yaml_path, device_str='cpu'):\n",
        "    global results_summary\n",
        "    metrics_data = {\n",
        "        \"mAP50-95\": float('nan'), \"mAP50\": float('nan'), \"mAP75\": float('nan'),\n",
        "        \"Precision\": float('nan'), \"Recall\": float('nan'), \"F1\": float('nan'),\n",
        "        \"time_ms\": float('nan')\n",
        "    }\n",
        "    try:\n",
        "        start_val_time = time.time()\n",
        "        if not isinstance(model_to_eval, YOLO):\n",
        "            model_to_eval = YOLO(str(model_to_eval))\n",
        "\n",
        "        metrics_obj = model_to_eval.val(data=data_yaml_path, split='val', device=device_str, plots=False, batch=1)\n",
        "        end_val_time = time.time()\n",
        "\n",
        "        if metrics_obj and hasattr(metrics_obj, 'box') and hasattr(metrics_obj.box, 'map'):\n",
        "            metrics_data[\"mAP50-95\"] = metrics_obj.box.map\n",
        "            metrics_data[\"mAP50\"] = metrics_obj.box.map50\n",
        "            metrics_data[\"mAP75\"] = metrics_obj.box.map75\n",
        "            if hasattr(metrics_obj.box, 'p') and isinstance(metrics_obj.box.p, np.ndarray) and metrics_obj.box.p.size > 0:\n",
        "                metrics_data[\"Precision\"] = np.mean(metrics_obj.box.p)\n",
        "            elif hasattr(metrics_obj.box, 'p'):\n",
        "                metrics_data[\"Precision\"] = metrics_obj.box.p\n",
        "            if hasattr(metrics_obj.box, 'r') and isinstance(metrics_obj.box.r, np.ndarray) and metrics_obj.box.r.size > 0:\n",
        "                metrics_data[\"Recall\"] = np.mean(metrics_obj.box.r)\n",
        "            elif hasattr(metrics_obj.box, 'r'):\n",
        "                metrics_data[\"Recall\"] = metrics_obj.box.r\n",
        "            if hasattr(metrics_obj.box, 'f1') and isinstance(metrics_obj.box.f1, np.ndarray) and metrics_obj.box.f1.size > 0:\n",
        "                metrics_data[\"F1\"] = np.mean(metrics_obj.box.f1)\n",
        "            elif hasattr(metrics_obj.box, 'f1'):\n",
        "                 metrics_data[\"F1\"] = metrics_obj.box.f1\n",
        "        if hasattr(metrics_obj, 'speed') and 'inference' in metrics_obj.speed:\n",
        "            metrics_data[\"time_ms\"] = metrics_obj.speed['preprocess'] + metrics_obj.speed['inference'] + metrics_obj.speed['postprocess']\n",
        "        else:\n",
        "             num_images = len(metrics_obj.dataset.im_files) if hasattr(metrics_obj, 'dataset') and hasattr(metrics_obj.dataset, 'im_files') else 0\n",
        "             if num_images > 0:\n",
        "                metrics_data[\"time_ms\"] = ((end_val_time - start_val_time) / num_images) * 1000\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR during validation of {model_id_str}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    results_summary[model_id_str] = metrics_data\n",
        "\n",
        "if ABS_DATASET_YAML_PATH and Path(ABS_DATASET_YAML_PATH).exists():\n",
        "    yolo_base_model = YOLO(MODEL_PT)\n",
        "\n",
        "    if yolo_base_model:\n",
        "        try:\n",
        "            fp32_export_path_obj_dir = yolo_base_model.export(\n",
        "                format='openvino', half=False, project=EXPORT_DIR_BASE, name=f\"{Path(MODEL_PT).stem}_ov_fp32\"\n",
        "            )\n",
        "            fp32_ov_model_path = Path(fp32_export_path_obj_dir) / (Path(MODEL_PT).stem + \".xml\")\n",
        "            if not fp32_ov_model_path.is_file():\n",
        "                found_xmls = list(Path(fp32_export_path_obj_dir).glob(\"*.xml\"))\n",
        "                if found_xmls: fp32_ov_model_path = found_xmls[0]\n",
        "                else: raise FileNotFoundError(f\"OpenVINO FP32 XML not found in {fp32_export_path_obj_dir}\")\n",
        "\n",
        "            validate_and_store_results(str(fp32_ov_model_path), \"OpenVINO FP32\", ABS_DATASET_YAML_PATH, device_str='cpu')\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR during OpenVINO FP32: {e}\")\n",
        "            results_summary[\"OpenVINO FP32\"] = {\"mAP50-95\": float('nan'), \"mAP50\": float('nan'), \"mAP75\": float('nan'), \"Precision\": float('nan'), \"Recall\": float('nan'), \"F1\": float('nan'), \"time_ms\": float('nan')}\n",
        "\n",
        "    if yolo_base_model:\n",
        "        try:\n",
        "            int8_export_path_obj_dir = yolo_base_model.export(\n",
        "                format='openvino', int8=True, data=ABS_DATASET_YAML_PATH, project=EXPORT_DIR_BASE, name=f\"{Path(MODEL_PT).stem}_ov_int8\"\n",
        "            )\n",
        "            int8_ov_model_path = Path(int8_export_path_obj_dir) / (Path(MODEL_PT).stem + \".xml\")\n",
        "            if not int8_ov_model_path.is_file():\n",
        "                found_xmls = list(Path(int8_export_path_obj_dir).glob(\"*.xml\"))\n",
        "                if found_xmls: int8_ov_model_path = found_xmls[0]\n",
        "                else: raise FileNotFoundError(f\"OpenVINO INT8 XML not found in {int8_export_path_obj_dir}\")\n",
        "\n",
        "            validate_and_store_results(str(int8_ov_model_path), \"OpenVINO INT8\", ABS_DATASET_YAML_PATH, device_str='cpu')\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR during OpenVINO INT8: {e}\")\n",
        "            results_summary[\"OpenVINO INT8\"] = {\"mAP50-95\": float('nan'), \"mAP50\": float('nan'), \"mAP75\": float('nan'), \"Precision\": float('nan'), \"Recall\": float('nan'), \"F1\": float('nan'), \"time_ms\": float('nan')}\n",
        "else:\n",
        "    print(\"ERROR: Dataset YAML path is not valid. Cannot proceed with evaluations.\")"
      ],
      "metadata": {
        "id": "2U6d23KYT6MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Overall Performance Summary (val2017 on CPU) ---\")\n",
        "header = (f\"{'Model':<25} | {'mAP@.5':<10} | {'mAP@.75':<10} | {'mAP@.5-.95':<12} | \"\n",
        "          f\"{'Precision':<10} | {'Recall':<10} | {'F1-score':<10} | \"\n",
        "          f\"{'Time (ms/img)':<15} | {'Speed-up vs PT FP32':<20}\")\n",
        "separator = \"-\" * (len(header) + 5)\n",
        "print(header)\n",
        "print(separator)\n",
        "\n",
        "baseline_time_ms = results_summary.get(\"PyTorch FP32\", {}).get(\"time_ms\", float('nan'))\n",
        "if np.isnan(baseline_time_ms) and \"PyTorch FP32\" not in results_summary:\n",
        "    print(\"NOTE: PyTorch FP32 baseline not run or metrics unavailable. Speed-up calculations will be N/A.\")\n",
        "\n",
        "model_order = [\"PyTorch FP32\", \"OpenVINO FP32\", \"OpenVINO INT8\"]\n",
        "evaluated_models_in_order = [m for m in model_order if m in results_summary]\n",
        "remaining_models = [m for m in results_summary if m not in evaluated_models_in_order]\n",
        "final_print_order = evaluated_models_in_order + remaining_models\n",
        "\n",
        "for model_name in final_print_order:\n",
        "    metrics = results_summary.get(model_name, {})\n",
        "    map_val = metrics.get(\"mAP50-95\", float('nan'))\n",
        "    map50_val = metrics.get(\"mAP50\", float('nan'))\n",
        "    map75_val = metrics.get(\"mAP75\", float('nan'))\n",
        "    precision_val = metrics.get(\"Precision\", float('nan'))\n",
        "    recall_val = metrics.get(\"Recall\", float('nan'))\n",
        "    f1_val = metrics.get(\"F1\", float('nan'))\n",
        "    time_val = metrics.get(\"time_ms\", float('nan'))\n",
        "\n",
        "    speed_up_str = \"N/A\"\n",
        "    if model_name == \"PyTorch FP32\" and not np.isnan(time_val):\n",
        "        speed_up_str = \"Baseline\"\n",
        "    elif \"PyTorch FP32\" in results_summary and not np.isnan(baseline_time_ms) and baseline_time_ms > 0 and not np.isnan(time_val) and time_val > 0:\n",
        "        speed_up = baseline_time_ms / time_val\n",
        "        speed_up_str = f\"{speed_up:.2f}x\"\n",
        "\n",
        "    print(f\"{model_name:<25} | {map50_val:<10.4f} | {map75_val:<10.4f} | {map_val:<12.4f} | \"\n",
        "          f\"{precision_val:<10.4f} | {recall_val:<10.4f} | {f1_val:<10.4f} | \"\n",
        "          f\"{time_val:<15.2f} | {speed_up_str:<20}\")\n",
        "\n",
        "if not results_summary:\n",
        "    print(\"No results found in results_summary to display.\")"
      ],
      "metadata": {
        "id": "5ybMPcmjT6Ob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}